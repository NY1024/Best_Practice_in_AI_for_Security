



人工智能技术可以辅助安全，也容易受到安全攻击。

人工智能分为三阶段，推理阶段、知识工程阶段、数据挖掘阶段。



人工智能可以节省人力成本，比如进行自动化威胁分析、自动化故障处理、安全运营等。

比如人工智能技术可以监控所有流入与流出的网络流量，并挖掘可疑模式、进行分类、预测等。

检测恶意软件



现在将AI应用于网络空间安全，其实已经不再局限于传统的安全了。比如内容安全，传统上大家不重视，但是现在的时代，每个人都可以发声，抖音、微博、小红书都属于UGC，内容安全、政治形态。用人力很难，但是用机器学习未必可以彻底解决。比如之前微信用AI防止大家分享某些新闻，是机器学习算法做的，但是大家以为是得到了政府的授意，于是情绪更加暴躁。



AI自动的攻防对抗，就像是两个AI对话一样。传统是人的对抗。你设置了目标，但是可能损失函数没有定义好，导致AI会找到不一样的解，而这个解人类根本想象不到。比如AlphaGo下棋时，走的路子就很野，人类根本不会这么下。对于时间序列领域，可能AI可以考虑地比人类更长远，比如我在第二层，大佬在第五层，但是AI在大气层。



被动防御永远是落后于人的。AI可以做分类，怎么做的？基于历史数据。但是如果有新的方法，那就无效了。但是现在AI自我博弈，对抗学习，可以自己学到的新的攻击方式。换句话说，AI技术的发展同样有助于安全领域从被动防御到主动防御的转型。



AI由数学家提供，普通的程序员尚且不重视安全，何况数学家。比如现在的MLaaS，提供API，大家知道API安全的，比如会做风险控制，比如限制查询次数，但是如果AI不做，那么容易受到成员推理攻击、白盒对抗攻击等。



可解释性非常重要

鲁棒性也非常重要



1998年的图灵奖的得主，吉姆格雷提到科学方法的一次革命，将科学研究的范式分为四类，除了实验范式、理论范式、仿真范式、还有第四范式，即数据密集型科学发现。

现在就是大数据的时代





特征工程，需要专家知识。



在Arp, Daniel, et al. "Dos and don’ts of machine learning in computer security." Proc. of the USENIX Security Symposium. 2022.指出了一些误区，如

采样偏差、标签缺失、虚假因果（相关性不代表因果性）等，这篇文章强烈推荐。



知识图谱也不应被忘记



内容安全：自然语言处理，舆情分析等；图像处理，涉黄等；视频分析，也是类似



P2DR模型

策略：定制策略、强化学习自己探索策略

防护：智能化fuzzing

检测：最多

响应：似乎没有

主动防御：基于强化学习的蜜罐、使用大预言模型如GPT3生成钓鱼文本邮件、文本挖掘-威胁情报分析



要选择好适合用AI解决的问题

有些问题适合用AI解决，有些不适合。比如加密数据分析，个人认为是不适合的，因为密文是混淆后的结果，统计信息等都已经被破坏。



也不能直接用已有的AI技术，比如自然语言和编程语言的区别，现在很多人直接拿Bert来用





脏数据怎么解决？

数据不够怎么办

数据敏感，无法联合怎么办？

这就涉及了联邦学习

或者某机构牵头，做一个benchmark数据集









但是AI不是银弹，不可能解决所有问题。AI本身就是问题。

模型部署在哪里？云端的话，延迟怎么解决？边缘端的话，算力怎么解决？传输的时候是否又会被攻击？



有些技术未必有用，比如针对基于AI的恶意软件检测器做对抗样本，尽管在特征空间有效，但是将其转为实际空间的时候，根本运行不了，比如损害了PE header等。





误报漏报的重要性问题。如果数据非常不平衡，模型哪怕训练地不好，也能直接预测是正常数据，可是有用吗？它漏报了，可是准确率却很高。



数据异构问题



AI模型的隐私问题，如果用了安全数据训练，可以推理出训练数据，这些数据如果是敏感的，那怎么办？

将模型本身当做载体，比如藏入payload，藏入信息等。

这比传统的隐写更难处理，因为模型本身不可解释性，都是权重，在人眼看来毫无意义。



AI会将security转为safety，因为会将人工智能决策转为实际动作，比如门禁、自动驾驶、医疗影像分析等





数据号称是新石油。

大数据可能是好事，也可能是坏事。比如安全大数据，处理的后，往前可以溯源，往后可以预判。但是如果处理不好，则会造成数据灾难。机器学习行业面临的问题，当这种技术应用于安全行业时同时会存在，如如何实现online learning等。



AI可解释性非常重要，尤其应用于敏感行业，大家都以自动驾驶为例，但是对于安全行业同样如此。

现在的AIGC很火，是否可以将其用于生成安全数据，弥补传统情况下面临的数据不平衡问题。



人工智能内生安全问题同样重要，相关的信息可以看我创建的另一个仓库。



受限于个人经验与能力，本文仅做抛砖引玉只用，欢迎大家交流。





数字安全、物理安全、政治安全

语音合成-克隆冒充本人，鱼叉式网络攻击、自动挖掘漏洞等

剑桥分析公司，进行有针对性的宣传和欺骗，隐私入侵、社交操纵，加选票



定制化钓鱼，可以针对社交网络上特定用户群体发送其感兴趣的钓鱼推文：收集已知的用户行为使用AI技术对用户进行分类，如果用户较为容易受到蛊惑且具有较高的价值，SNAP-R会使用递归神经网络技术对用户发表的历史推文，用户的回复等信息生成虚假的推文内容，并在其中植入钓鱼链接。相较于传统技术，将钓鱼成功率提升了30%-35%



强化学习-自动化渗透测试



Human-in-the-loop对于提升透明度和可解释性也很重要，比如ChatGPT的人类参与提示训练师



由于硬件资源限制、实时监测等，DL未必好，可能机器学习会更适合



欠缺高质量的数据集，zero-short learning、数据增强、数据合成。



第一代：符号与逻辑

第二代：机器学习，基于统计学习，依赖于特征提取，而这需要专家参与，专家没有定义到特征，那么就不够完善。

第三代：深度学习，不需要抽取特征，可以直接对原数据进行训练。比如人脸识别，机器学习会用肤色、文理等特征抽出来代表人脸进行训练，深度学习则直接用人脸进行训练



数据没有这么容易拿到，传统的CV数据集，可以放在亚马孙的众包平台上，随便什么人都能标注，但是安全数据，只有安全专家能标注。那么人力成本一下子就上去了。而且数据可能涉及隐私问题，比如流量数据，如果没有处理好，可能会泄露拓扑环境。



样本分布差，因为是在实验室环境、静态



比如入侵检测，数据集可以分为原始数据和结构化数据，前者是实验室流量模拟器等方式收集，后者可能是真实数据集但是已经被脱敏、筛选过了，意义有限。

另一篇推荐的论文是Outside the Closed World: On Using Machine Learning For Network Intrusion Detection



AI应用于安全时，有许多需要注意的第发，比如误判的代价极高，数据复杂性导致难以判断等



选择可解释的特征，避免错误的模型检测因果关系。比如入侵检测中对于流量的选择。可能机器学习模型会将公网ip当做特征用于攻击分类。



在样本量不够的情况下，不要盲目上深度学习。



张钹院士这篇文章推荐看看“https://mp.weixin.qq.com/s/6L5B2DuZLTSnSr_TSamoyg”







